{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5NSlDb5nBwKxbcwLmgZwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyson0427/CPSC585_AS3/blob/main/CPSC585_AS3_20240420.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sCTDpRaTHicm",
        "outputId": "75183876-879e-46a7-cbb2-d01faa2741f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CUDA version is 12.1\n",
            "ID of the CUDA device: 0\n",
            "The name of the CUDA device: Tesla T4\n",
            "GPU will be utilized for computation.\n",
            "------------------ANN modeling---------------------------\n",
            "> Shape of training data: torch.Size([60000, 28, 28])\n",
            "> Shape of testing data: torch.Size([10000, 28, 28])\n",
            "> Classes: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
            "> Mini batch size:  100\n",
            "> Number of batches loaded for training:  600\n",
            "> Number of batches loaded for testing:  100\n",
            "> Shapes of image: torch.Size([100, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> MLP model parameters\n",
            "<bound method Module.parameters of MLP(\n",
            "  (hidden1): Linear(in_features=784, out_features=12, bias=True)\n",
            "  (output): Linear(in_features=12, out_features=18, bias=True)\n",
            ")>\n",
            "> MLP model's state dictionary\n",
            "hidden1.weight torch.Size([12, 784])\n",
            "hidden1.bias torch.Size([12])\n",
            "output.weight torch.Size([18, 12])\n",
            "output.bias torch.Size([18])\n",
            "output_size :  24.0 w :  12.0   num_flatten_nodes:  1440\n",
            "> CNN model parameters\n",
            "<bound method Module.parameters of CNN(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (drop2D): Dropout2d(p=0.25, inplace=False)\n",
            "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=160, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")>\n",
            "...Modeling using GPU...\n",
            "> MLP optimizer's state dictionary\n",
            "state {}\n",
            "param_groups [{'lr': 1.0, 'rho': 0.3, 'eps': 1e-06, 'weight_decay': 0, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3]}]\n",
            "............Training MLP................\n",
            "Epoch=1/1, batch=100/600, loss=1.2797930240631104\n",
            "Epoch=1/1, batch=200/600, loss=0.7898266315460205\n",
            "Epoch=1/1, batch=300/600, loss=0.5638594627380371\n",
            "Epoch=1/1, batch=400/600, loss=0.397734671831131\n",
            "Epoch=1/1, batch=500/600, loss=0.6981419324874878\n",
            "Epoch=1/1, batch=600/600, loss=0.5797478556632996\n",
            "............Testing MLP model................\n",
            "> Input digits:\n",
            "tensor([0, 5, 0, 0, 2, 8, 1, 0, 6, 7, 2, 0, 1, 2, 1, 2, 1, 2, 0, 7, 9, 8, 2, 8,\n",
            "        3, 8, 9, 0, 7, 4, 9, 7, 3, 5, 0, 9, 4, 1, 4, 3, 7, 5, 1, 1, 1, 3, 9, 0,\n",
            "        6, 1, 7, 8, 8, 8, 7, 2, 2, 0, 1, 9, 5, 3, 8, 4, 6, 2, 1, 0, 6, 4, 6, 2,\n",
            "        2, 3, 7, 1, 9, 1, 3, 6, 5, 2, 4, 7, 0, 4, 9, 9, 8, 8, 8, 8, 9, 2, 6, 1,\n",
            "        9, 6, 8, 8])\n",
            "batch=100/100\n",
            "> Number of samples= 100 number of correct prediction= 81 accuracy= 0.81\n",
            "............Training CNN................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c88f677ce865>:97: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return AF.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=1/1, batch=100/600, loss=0.2812919318675995\n",
            "Epoch=1/1, batch=200/600, loss=0.19709546864032745\n",
            "Epoch=1/1, batch=300/600, loss=0.12003348022699356\n",
            "Epoch=1/1, batch=400/600, loss=0.12884946167469025\n",
            "Epoch=1/1, batch=500/600, loss=0.06160662695765495\n",
            "Epoch=1/1, batch=600/600, loss=0.08550801128149033\n",
            "............Testing CNN model................\n",
            "batch=100/100\n",
            "> Number of samples= 100 number of correct prediction= 98 accuracy= 0.98\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import torch.nn.functional as AF\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "###################### Designing an ANN architectures #########################\n",
        "### MLP architecture\n",
        "class MLP(nn.Module): # All models should inherit from nn.Module\n",
        "    # This part can be changed based on the design decision.\n",
        "    def __init__(self, num_input, hidden1_size, num_classes): # Define our ANN structures here\n",
        "        super(MLP, self).__init__()\n",
        "        # nn.Linear(in_features, out_features, bias): y = w^Tx + bias\n",
        "        self.hidden1 = nn.Linear(num_input, hidden1_size)    # connection between input and hidden layer1\n",
        "        self.output = nn.Linear(hidden1_size, num_classes)\n",
        "\n",
        "        # The model structure can be also defined using \"sequential\" function\n",
        "        # self.seq_linear=nn.Sequential(nn.Linear(num_input, hidden1_size),nn.RELU(),nn.Linear(hidden1_size, num_classes))\n",
        "\n",
        "    # Define \"forward\" function to perform the computation for input x and return output(s).\n",
        "    # The function name \"forward\" is required by Pytorch.\n",
        "    def forward(self, x):\n",
        "        # In this implementation, the activation function is reLU, but you can try other functions\n",
        "        # torch.nn.functional modeule consists of all the activation functions and output functions\n",
        "        h1_out = AF.relu(self.hidden1(x)) # best activation function\n",
        "        #h1_out = AF.sigmoid(self.hidden1(x))\n",
        "        #h1_out = AF.tanh(self.hidden1(x))\n",
        "        #h1_out = AF.softmax(self.hidden1(x))\n",
        "        output = self.output(h1_out)\n",
        "        # AF.softmax() is NOT needed when CrossEntropyLoss() is used as it already combines both LogSoftMax() and NLLLoss()\n",
        "\n",
        "        # return self.seq_linear(x) # If the model structrue is define by sequential function.\n",
        "        return output\n",
        "\n",
        "### CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    # The probability of dropout, number of hidden nodes, number of output classes\n",
        "    def __init__(self, dropout_pr, num_hidden, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.pool_size = 2\n",
        "        self.filter_size = 5 # 1, 5 tested\n",
        "        self.stride = 1\n",
        "        self.output_size = ((28 - self.filter_size) / self.stride ) + 1\n",
        "        self.w = ((self.output_size - self.pool_size) / self.pool_size) + 1\n",
        "        self.num_flatten_nodes = int(num_classes * self.w * self.w)\n",
        "        print('output_size : ', self.output_size, 'w : ', self.w, '  num_flatten_nodes: ', self.num_flatten_nodes)\n",
        "\n",
        "        # convolutional layer = 1\n",
        "        #self.conv1 = nn.Conv2d(1, num_classes, self.filter_size)\n",
        "        #self.pool1 = nn.MaxPool2d(self.pool_size, self.pool_size)\n",
        "        #self.dropout_conv1 = nn.Dropout2d(dropout_pr)\n",
        "        #self.fc1 = nn.Linear(self.num_flatten_nodes, num_hidden)\n",
        "        #self.out = nn.Linear(num_hidden, num_classes)\n",
        "\n",
        "        # convolutional layer = 2\n",
        "        self.conv1 = nn.Conv2d(1, 10, self.filter_size) # input_channel = 1, filter = 10\n",
        "        # ((W-K+2P)/S + 1 ==> 24, by maxpooling it will be 12 * 12)\n",
        "        # when pool size is 3, it will be 8*8\n",
        "        self.conv2 = nn.Conv2d(10, 10, self.filter_size)\n",
        "        # new w = 12\n",
        "        # ((W-K+2P)/S + 1 ==> 8, by maxpooling it will be 4*4)\n",
        "\n",
        "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)\n",
        "        self.mp = nn.MaxPool2d(self.pool_size)\n",
        "        #self.mp = nn.AvgPool2d(self.pool_size)\n",
        "        #self.fc1 = nn.Linear(160, 10) # 4*4*10 Vector\n",
        "\n",
        "        self.fc1 = nn.Linear(160, 100)\n",
        "        self.fc2 = nn.Linear(100, 10) # to 10 outputs\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # convolutional layer = 1\n",
        "      #x = AF.relu(self.pool1(self.conv1(x)))\n",
        "      #x = AF.relu(self.dropout_conv1(x))\n",
        "      #x = x.view(-1, self.num_flatten_nodes)\n",
        "      #x = AF.relu(self.fc1(x))\n",
        "      #x = AF.dropout(x)\n",
        "      #x = self.out(x)\n",
        "      #return x\n",
        "\n",
        "      # convolutional layer = 2\n",
        "      x = AF.relu(self.mp(self.conv1(x)))\n",
        "      x = AF.relu(self.mp(self.conv2(x)))\n",
        "      #x = AF.sigmoid(self.mp(self.conv1(x)))\n",
        "      #x = AF.sigmoid(self.mp(self.conv2(x)))\n",
        "      #x = AF.tanh(self.mp(self.conv1(x)))\n",
        "      #x = AF.tanh(self.mp(self.conv2(x)))\n",
        "      #x = AF.softmax(self.mp(self.conv1(x)))\n",
        "      #x = AF.softmax(self.mp(self.conv2(x)))\n",
        "      x = self.drop2D(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      x = self.fc1(x)\n",
        "      x = self.fc2(x)\n",
        "      return AF.log_softmax(x)\n",
        "\n",
        "\n",
        "# To display some images\n",
        "def show_some_digit_images(images):\n",
        "    print(\"> Shapes of image:\", images.shape)\n",
        "    #print(\"Matrix for one image:\")\n",
        "    #print(images[1][0])\n",
        "    for i in range(0, 10):\n",
        "        plt.subplot(2, 5, i+1) # Display each image at i+1 location in 2 rows and 5 columns (total 2*5=10 images)\n",
        "        plt.imshow(images[i][0], cmap='Oranges') # show ith image from image matrices by color map='Oranges'\n",
        "    plt.show()\n",
        "\n",
        "# Training function\n",
        "def train_ANN_model(num_epochs, training_data, device, CUDA_enabled, is_MLP, ANN_model, loss_func, optimizer):\n",
        "    train_losses = []\n",
        "    ANN_model.train() # to set the model in training mode. Only Dropout and BatchNorm care about this flag.\n",
        "    for epoch_cnt in range(num_epochs):\n",
        "        for batch_cnt, (images, labels) in enumerate(training_data):\n",
        "            # Each batch contain batch_size (100) images, each of which 1 channel 28x28\n",
        "            # print(images.shape) # the shape of images=[100,1,28,28]\n",
        "            # So, we need to flatten the images into 28*28=784\n",
        "            # -1 tells NumPy to flatten to 1D (784 pixels as input) for batch_size images\n",
        "            if (is_MLP):\n",
        "                # the size -1 is inferred from other dimensions\n",
        "                images = images.reshape(-1, 784) # or images.view(-1, 784) or torch.flatten(images, start_dim=1)\n",
        "\n",
        "            if (device.type == 'cuda' and CUDA_enabled):\n",
        "                images = images.to(device) # moving tensors to device\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad() # set the cumulated gradient to zero\n",
        "            output = ANN_model(images) # feedforward images as input to the network\n",
        "            loss = loss_func(output, labels) # computing loss\n",
        "            #print(\"Loss: \", loss)\n",
        "            #print(\"Loss item: \", loss.item())\n",
        "            train_losses.append(loss.item())\n",
        "            # PyTorch's Autograd engine (automatic differential (chain rule) package)\n",
        "            loss.backward() # calculating gradients backward using Autograd\n",
        "            optimizer.step() # updating all parameters after every iteration through backpropagation\n",
        "\n",
        "            # Display the training status\n",
        "            if (batch_cnt+1) % mini_batch_size == 0:\n",
        "                print(f\"Epoch={epoch_cnt+1}/{num_epochs}, batch={batch_cnt+1}/{num_train_batches}, loss={loss.item()}\")\n",
        "    return train_losses\n",
        "\n",
        "# Testing function\n",
        "def test_ANN_model(device, CUDA_enabled, is_MLP, ANN_model, testing_data):\n",
        "    # torch.no_grad() is a decorator for the step method\n",
        "    # making \"require_grad\" false since no need to keeping track of gradients\n",
        "    predicted_digits=[]\n",
        "    # torch.no_grad() deactivates Autogra engine (for weight updates). This help run faster\n",
        "    with torch.no_grad():\n",
        "        ANN_model.eval() # # set the model in testing mode. Only Dropout and BatchNorm care about this flag.\n",
        "        for batch_cnt, (images, labels) in enumerate(testing_data):\n",
        "            if (is_MLP):\n",
        "                images = images.reshape(-1, 784) # or images.view(-1, 784) or torch.flatten(images, start_dim=1)\n",
        "\n",
        "            if (device.type == 'cuda' and CUDA_enabled):\n",
        "                images = images.to(device) # moving tensors to device\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            output = ANN_model(images)\n",
        "            _, prediction = torch.max(output,1) # returns the max value of all elements in the input tensor\n",
        "            predicted_digits.append(prediction)\n",
        "            num_samples = labels.shape[0]\n",
        "            num_correct = (prediction==labels).sum().item()\n",
        "            accuracy = num_correct/num_samples\n",
        "            if (batch_cnt+1) % mini_batch_size == 0:\n",
        "                print(f\"batch={batch_cnt+1}/{num_test_batches}\")\n",
        "        print(\"> Number of samples=\", num_samples, \"number of correct prediction=\", num_correct, \"accuracy=\", accuracy)\n",
        "    return predicted_digits\n",
        "\n",
        "########################### Checking GPU and setup #########################\n",
        "### CUDA is a parallel computing platform and toolkit developed by NVIDIA.\n",
        "# CUDA enables parallelize the computing intensive operations using GPUs.\n",
        "# In order to use CUDA, your computer needs to have a CUDA supported GPU and install the CUDA Toolkit\n",
        "# Steps to verify and setup Pytorch and CUDA Toolkit to utilize your GPU in your machine:\n",
        "# (1) Check if your computer has a compatible GPU at https://developer.nvidia.com/cuda-gpus\n",
        "# (2) If you have a GPU, continue to the next step, else you can only use CPU and ignore the rest steps.\n",
        "# (3) Downloaded the compatible Pytorch version and CUDA version, refer to https://pytorch.org/get-started/locally/\n",
        "# Note: If Pytorch and CUDA versions are not compatible, Pytorch will not be able to recognize your GPU\n",
        "# (4) The following codes will verify if Pytorch is able to recognize the CUDA Toolkit:\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "if (torch.cuda.is_available()):\n",
        "    print(\"The CUDA version is\", torch.version.cuda)\n",
        "    # Device configuration: use GPU if available, or use CPU\n",
        "    cuda_id = torch.cuda.current_device()\n",
        "    print(\"ID of the CUDA device:\", cuda_id)\n",
        "    print(\"The name of the CUDA device:\", torch.cuda.get_device_name(cuda_id))\n",
        "    print(\"GPU will be utilized for computation.\")\n",
        "else:\n",
        "    print(\"CUDA is supported in your machine. Only CPU will be used for computation.\")\n",
        "#exit()\n",
        "\n",
        "############################### ANN modeling #################################\n",
        "### Convert the image into numbers: transforms.ToTensor()\n",
        "# It separate the image into three color channels RGB and converts the pixels of each images to the brightness\n",
        "# of the color in the range [0,255] that are scaled down to a range [0,1]. The image is now a Torch Tensor (array object)\n",
        "### Normalize the tensor: transforms.Normalize() normalizes the tensor with mean (0.5) and stdev (0.5)\n",
        "#+ You can change the mean and stdev values\n",
        "print(\"------------------ANN modeling---------------------------\")\n",
        "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,)),])\n",
        "# PyTorch tensors are like NumPy arrays that can run on GPU\n",
        "# e.g., x = torch.randn(64,100).type(dtype) # need to cast tensor to a CUDA datatype (dtype)\n",
        "\n",
        "from torch.autograd import Variable\n",
        "x = Variable\n",
        "\n",
        "### Download and load the dataset from the torch vision library to the directory specified by root=''\n",
        "# MNIST is a collection of 7000 handwritten digits (in images) split into 60000 training images and 1000 for testing\n",
        "# PyTorch library provides a clean data set. The following command will download training data in directory './data'\n",
        "train_dataset=datasets.MNIST(root='./data', train=True, transform=transforms, download=True)\n",
        "test_dataset=datasets.MNIST(root='./data', train=False, transform=transforms, download=False)\n",
        "print(\"> Shape of training data:\", train_dataset.data.shape)\n",
        "print(\"> Shape of testing data:\", test_dataset.data.shape)\n",
        "print(\"> Classes:\", train_dataset.classes)\n",
        "\n",
        "# You can use random_split function to splite a dataset\n",
        "#from torch.utils.data.dataset import random_split\n",
        "#train_data, val_data, test_data = random_split(train_dataset, [60,20,20])\n",
        "\n",
        "### DataLoader will shuffle the training dataset and load the training and test dataset\n",
        "mini_batch_size = 100 #+ You can change this mini_batch_size\n",
        "# If mini_batch_size==100, # of training batches=6000/100=600 batches, each batch contains 100 samples (images, labels)\n",
        "# DataLoader will load the data set, shuffle it, and partition it into a set of samples specified by mini_batch_size.\n",
        "train_dataloader=DataLoader(dataset=train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
        "test_dataloader=DataLoader(dataset=test_dataset, batch_size=mini_batch_size, shuffle=True)\n",
        "num_train_batches = len(train_dataloader)\n",
        "num_test_batches = len(test_dataloader)\n",
        "print(\"> Mini batch size: \", mini_batch_size)\n",
        "print(\"> Number of batches loaded for training: \", num_train_batches)\n",
        "print(\"> Number of batches loaded for testing: \", num_test_batches)\n",
        "\n",
        "### Let's display some images from the first batch to see what actual digit images look like\n",
        "iterable_batches = iter(train_dataloader) # making a dataset iterable\n",
        "images, labels = next(iterable_batches) # If you can call next() again, you get the next batch until no more batch left\n",
        "show_digit_image = True\n",
        "if show_digit_image:\n",
        "    show_some_digit_images(images)\n",
        "\n",
        "### Create an object for the ANN model defined in the MLP class\n",
        "# Architectural parameters: You can change these parameters except for num_input and num_classes\n",
        "num_input = 28*28   # 28X28=784 pixels of image\n",
        "num_classes_mlp = 18    # output layer\n",
        "num_hidden_mlp = 12     # number of neurons at the first hidden layer\n",
        "\n",
        "num_classes_cnn = 10 # output layer of CNN model\n",
        "num_hidden_cnn = 20 # number of neurons at the first hidden layer\n",
        "\n",
        "# Randomly selected neurons by dropout_pr probability will be dropped (zeroed out) for regularization.\n",
        "dropout_pr = 0.01\n",
        "\n",
        "\n",
        "# MLP model\n",
        "MLP_model=MLP(num_input, num_hidden_mlp, num_classes_mlp)\n",
        "# Some model properties:\n",
        "# .state_dic(): a dictionary of trainable parameters with their current valeus\n",
        "# .parameter(): a list of all trainable parameters in the model\n",
        "# .train() or .eval(): setting training, testing mode\n",
        "\n",
        "print(\"> MLP model parameters\")\n",
        "print(MLP_model.parameters)\n",
        "# state_dict() maps each layer to its parameter tensor.\n",
        "print (\"> MLP model's state dictionary\")\n",
        "for param_tensor in MLP_model.state_dict():\n",
        "    print(param_tensor, MLP_model.state_dict()[param_tensor].size())\n",
        "\n",
        "#exit()\n",
        "\n",
        "# CNN model\n",
        "CNN_model = CNN(dropout_pr, num_hidden_cnn, num_classes_cnn)\n",
        "print(\"> CNN model parameters\")\n",
        "print(CNN_model.parameters)\n",
        "\n",
        "# To turn on/off CUDA if I don't want to use it.\n",
        "CUDA_enabled = True\n",
        "if (device.type == 'cuda' and CUDA_enabled):\n",
        "    print(\"...Modeling using GPU...\")\n",
        "    MLP_model = MLP_model.to(device=device) # sending to whaever device (for GPU acceleration)\n",
        "    CNN_model = CNN_model.to(device=device)\n",
        "else:\n",
        "    print(\"...Modeling using CPU...\")\n",
        "\n",
        "### Define a loss function: You can choose other loss functions\n",
        "loss_func = nn.CrossEntropyLoss() # for MLP\n",
        "#loss_func_cnn = nn.CrossEntropyLoss() # for CNN\n",
        "loss_func_cnn = nn.NLLLoss() # for CNN\n",
        "\n",
        "### Choose a gradient method\n",
        "# model hyperparameters and gradient methods\n",
        "# optim.SGD performs gradient descent and update the weigths through backpropagation.\n",
        "num_epochs = 1\n",
        "alpha = 0.02       # learning rate for MLP\n",
        "gamma = 0.3       # momentum for MLP\n",
        "\n",
        "gamma_cnn = 0.3       # momentum for CNN\n",
        "\n",
        "# Stochastic Gradient Descent (SGD) is used in this program.\n",
        "#+ You can choose other gradient methods (Adagrad, adadelta, Adam, etc.) and parameters\n",
        "#MLP_optimizer = optim.SGD(MLP_model.parameters(), lr=alpha, momentum=gamma)\n",
        "#MLP_optimizer = optim.Adagrad(MLP_model.parameters(), lr=alpha)\n",
        "MLP_optimizer = optim.Adadelta(MLP_model.parameters(), rho = gamma, eps = 1e-6)\n",
        "#MLP_optimizer = optim.RMSprop(MLP_model.parameters(), lr=alpha, alpha=0.99, eps=1e-8)\n",
        "#MLP_optimizer = optim.Adam(MLP_model.parameters(), lr=alpha)\n",
        "print(\"> MLP optimizer's state dictionary\")\n",
        "for var_name in MLP_optimizer.state_dict():\n",
        "    print(var_name, MLP_optimizer.state_dict()[var_name])\n",
        "\n",
        "# CNN optimizer\n",
        "#CNN_optimizer = optim.SGD(CNN_model.parameters(), lr=alpha, momentum=gamma)\n",
        "CNN_optimizer = optim.Adagrad(CNN_model.parameters(), lr=alpha)\n",
        "#CNN_optimizer = optim.Adadelta(CNN_model.parameters(), rho = gamma_cnn, eps = 1e-6)\n",
        "#CNN_optimizer = optim.RMSprop(CNN_model.parameters(), lr=alpha, alpha=0.99, eps=1e-8)\n",
        "#CNN_optimizer = optim.Adam(CNN_model.parameters(), lr=alpha)\n",
        "\n",
        "### Train your networks\n",
        "print(\"............Training MLP................\")\n",
        "is_MLP = True\n",
        "train_loss=train_ANN_model(num_epochs, train_dataloader, device, CUDA_enabled, is_MLP, MLP_model, loss_func, MLP_optimizer)\n",
        "print(\"............Testing MLP model................\")\n",
        "print(\"> Input digits:\")\n",
        "print(labels)\n",
        "predicted_digits=test_ANN_model(device, CUDA_enabled, is_MLP, MLP_model, test_dataloader)\n",
        "#print(\"> Predicted digits by MLP model\")\n",
        "#print(predicted_digits)\n",
        "\n",
        "print(\"............Training CNN................\")\n",
        "is_MLP = False\n",
        "train_loss=train_ANN_model(num_epochs, train_dataloader, device, CUDA_enabled, is_MLP, CNN_model, loss_func_cnn, CNN_optimizer)\n",
        "print(\"............Testing CNN model................\")\n",
        "predicted_digits=test_ANN_model(device, CUDA_enabled, is_MLP, CNN_model, test_dataloader)\n",
        "\n",
        "#print(\"> Predicted digits by CNN model\")\n",
        "#print(predicted_digits)\n",
        "\n",
        "#### To save and load models and model's parameters ####\n",
        "# To save and load model parameters\n",
        "#print(\"...Saving and loading model states and model parameters...\")\n",
        "#torch.save(MLP_model.state_dict(), 'MLP_model_state_dict.pt')\n",
        "#loaded_MLP_model=MLP(num_input, num_hidden, num_classes)\n",
        "#loaded_MLP_model=MLP_model.load_state_dict(torch.load('MLP_model_state_dict.pt'))\n",
        "#torch.save(MLP_optimizer.state_dict(), 'MLP_optimizer_state_dict.pt')\n",
        "#loaded_MLP_optimizer = MLP_optimizer.load_state_dict(torch.load('MLP_optimizer_state_dict.pt'))\n",
        "\n",
        "# To save and load a model\n",
        "#print(\"...Saving model...\")\n",
        "#torch.save(MLP_model, 'MLP_model_NNIST.pt')\n",
        "#pretrained_model = torch.load('MLP_model_NNIST.pt')\n"
      ]
    }
  ]
}